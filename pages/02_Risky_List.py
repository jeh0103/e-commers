# pages/02_Risky_List.py
# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import numpy as np
import os, json
from urllib.parse import quote

st.set_page_config(page_title="ğŸ“‹ ì´íƒˆ ê³ ê° ë¦¬ìŠ¤íŠ¸", layout="wide")

# ===== í™”ë©´ í‘œì‹œìš© í•œê¸€ ë¼ë²¨ =====
KOR_COL = {
    "CustomerID_clean": "ê³ ê°ID",
    "GenderLabel": "ì„±ë³„",
    "Age": "ë‚˜ì´",
    "CustomerLifetimeValue": "ê³ ê°ìƒì• ê°€ì¹˜(CLV)",
    "TotalPurchases": "ì´ êµ¬ë§¤ íšŸìˆ˜",
    "PurchaseFrequency": "êµ¬ë§¤ ë¹ˆë„(ì›” í‰ê· )",
    "CSFrequency": "ìƒë‹´ ë¹ˆë„(ì›” í‰ê· )",
    "AverageSatisfactionScore": "í‰ê·  ë§Œì¡±ë„",
    "NegativeExperienceIndex": "ë¶€ì • ê²½í—˜ ì§€ìˆ˜",
    "EmailEngagementRate": "ì´ë©”ì¼ ì°¸ì—¬ìœ¨",
    "TotalEngagementScore": "ì´ í™œë™ ì ìˆ˜",
    "ChurnRiskScore": "ì´íƒˆ ìœ„í—˜ ì ìˆ˜",
    "RepeatAndPremiumFlag": "ë¦¬í”¼íŠ¸/í”„ë¦¬ë¯¸ì—„ ì—¬ë¶€",
    # ë‚´ë¶€ì ìœ¼ë¡œë§Œ ì‚¬ìš©í•˜ëŠ” ëª¨ë¸ ì ìˆ˜(í™”ë©´ í‘œì—ì„œëŠ” ìˆ¨ê¹€)
    "IF_AnomalyScore": "IF ì´ìƒì¹˜ì ìˆ˜",
    "AE_ReconError": "AE ì¬êµ¬ì„±ì˜¤ì°¨",
}

def rename_for_display(df: pd.DataFrame) -> pd.DataFrame:
    return df.rename(columns={c: KOR_COL.get(c, c) for c in df.columns})

# ===== ì„±ë³„ ë¼ë²¨ ë³´ì¥ =====
DEFAULT_CODE_TO_LABEL_KO = {1:"ì—¬ì„±",3:"ë‚¨ì„±",5:"ì‘ë‹µê±°ë¶€",4:"ê¸°íƒ€/ë¯¸ìƒ",2:"ë‚¨ì„±",0:"ì—¬ì„±"}

def _normalize_gender_text_to_label_ko(x) -> str:
    if x is None or (isinstance(x, float) and np.isnan(x)): return "ë¯¸ìƒ"
    s = str(x).strip().lower()
    if s in {"m","male","man","ë‚¨","ë‚¨ì„±"}: return "ë‚¨ì„±"
    if s in {"f","female","woman","ì—¬","ì—¬ì„±"}: return "ì—¬ì„±"
    if s in {"prefer not to say","decline to state","no answer"}: return "ì‘ë‹µê±°ë¶€"
    if s in {"non-binary","nonbinary","genderqueer","agender","nb","other","ê¸°íƒ€"}: return "ê¸°íƒ€"
    return "ê¸°íƒ€"

def ensure_gender_label(df_hybrid: pd.DataFrame,
                        original_csv_path: str = "ecommerce_customer_data.csv",
                        code_map_path: str = "gender_code_map.json") -> pd.DataFrame:
    df = df_hybrid.copy()
    if os.path.exists(original_csv_path):
        try:
            raw = pd.read_csv(original_csv_path, usecols=["CustomerID","Gender"])
            raw["GenderLabel_from_raw"] = raw["Gender"].map(_normalize_gender_text_to_label_ko)
            df = df.merge(raw[["CustomerID","GenderLabel_from_raw"]], on="CustomerID", how="left")
        except Exception:
            df["GenderLabel_from_raw"] = np.nan
    else:
        df["GenderLabel_from_raw"] = np.nan
    code_map = DEFAULT_CODE_TO_LABEL_KO.copy()
    if os.path.exists(code_map_path):
        try:
            with open(code_map_path, "r", encoding="utf-8") as f:
                loaded = json.load(f)
                code_map.update({int(k): v for k, v in loaded.items()})
        except Exception:
            pass
    label_from_code = df["Gender"].map(code_map) if "Gender" in df.columns else pd.Series(index=df.index, dtype="object")
    df["GenderLabel"] = df["GenderLabel_from_raw"].fillna(label_from_code)
    df.drop(columns=["GenderLabel_from_raw"], inplace=True)
    df["GenderLabel"] = df["GenderLabel"].fillna("ë¯¸ìƒ")
    return df

# ===== ë°ì´í„° ë¡œë”© =====
@st.cache_data(show_spinner=False)
def load_main():
    df = pd.read_csv("ecommerce_customer_churn_hybrid_with_id.csv")

    # CustomerID_clean ë³´ì¥
    def _clean_id(x):
        if pd.isna(x):
            return np.nan
        s = str(x).strip()
        return np.nan if (s == "" or s.lower() in {"nan", "none", "nat", "null"}) else s

    if "CustomerID" in df.columns:
        df["CustomerID_clean"] = df["CustomerID"].map(_clean_id)
    else:
        df["CustomerID_clean"] = np.nan

    
    if df["CustomerID_clean"].isna().all() or df["CustomerID_clean"].isna().any():
        generated = pd.Series(np.arange(1, len(df) + 1), index=df.index).map(lambda i: f"CUST{i:05d}")
        df["CustomerID_clean"] = df["CustomerID_clean"].fillna(generated)
        if "CustomerID" not in df.columns:
            df["CustomerID"] = df["CustomerID_clean"]

    df = ensure_gender_label(df)
    return df
df = load_main()

# ===== ì „ì—­ í•„í„°/ì„ê³„ê°’ ì„¸ì…˜ ê°’ ì¬ì‚¬ìš© =====
sel_age = st.session_state.get("sel_age")
sel_gender_labels = st.session_state.get("sel_gender_labels", [])
premium_opt = st.session_state.get("premium_opt", "ì „ì²´")
use_dynamic = bool(st.session_state.get("use_dynamic", False))
if_thr = st.session_state.get("if_thr")
ae_thr = st.session_state.get("ae_thr")

# í•„í„° ì ìš©
filtered = df.copy()
if sel_age:
    filtered = filtered[(filtered["Age"] >= sel_age[0]) & (filtered["Age"] <= sel_age[1])]
if sel_gender_labels:
    filtered = filtered[filtered["GenderLabel"].isin(sel_gender_labels)]
if "RepeatAndPremiumFlag" in filtered.columns and premium_opt != "ì „ì²´":
    filtered = filtered[filtered["RepeatAndPremiumFlag"] == (1 if str(premium_opt).startswith("ì˜ˆ") else 0)]

# ===== íŒŒë¼ë¯¸í„°: src (if|ae|both) =====
src = st.query_params.get("src", "both") if hasattr(st, "query_params") \
      else st.experimental_get_query_params().get("src", ["both"])[0]
src = (src if isinstance(src, str) else src[0]).lower()

# ===== ìƒë‹¨ ë„¤ë¹„ =====
try:
    st.page_link("app_enhanced.py", label="â¬…ï¸ ëŒ€ì‹œë³´ë“œë¡œ", icon="ğŸ ")
except Exception:
    st.markdown("[ğŸ  ëŒ€ì‹œë³´ë“œë¡œ](/)")

TITLE = {
    "if":   "ì´ìƒí–‰ë™ ê¸°ë°˜ ì´íƒˆ ì˜ì‹¬ ê³ ê°",
    "ae":   "íŒ¨í„´ ë³€í™” ê¸°ë°˜ ì´íƒˆ ì˜ì‹¬ ê³ ê°",
    "both": "ê³µí†µ ì´íƒˆ ê³ ê°(ê³ ì‹ ë¢°êµ°)"
}
st.title(f"ğŸ—‚ï¸ {TITLE.get(src, 'ê³ ê° ë¦¬ìŠ¤íŠ¸')}")

# ===== íŒë‹¨ ê¸°ì¤€/ê¸°ë³¸ ì„¤ì • =====
if src == "if":
    flag_col = "IF_ChurnFlag_dyn" if (use_dynamic and "IF_ChurnFlag_dyn" in filtered.columns) else "IF_ChurnFlag"
    sort_metric = "IF_AnomalyScore" if "IF_AnomalyScore" in filtered.columns else "ChurnRiskScore"
    subset = filtered[filtered.get(flag_col, 0) == 1] if flag_col in filtered.columns else filtered.copy()
    thr_value = float(if_thr) if (use_dynamic and if_thr is not None) else (
        float(filtered["IF_AnomalyScore"].quantile(0.95)) if "IF_AnomalyScore" in filtered.columns else None)
    st.markdown(
        "**íŒë‹¨ ê¸°ì¤€ ì•ˆë‚´**\n\n"
        "- Isolation ForestëŠ” ê²©ë¦¬ ê¹Šì´ë¡œ ì´ìƒì¹˜ ì ìˆ˜ë¥¼ ê³„ì‚°í•˜ë©°, ì ìˆ˜ê°€ í´ìˆ˜ë¡ ì´íƒˆ ì‹ í˜¸ë¡œ ê°„ì£¼í•©ë‹ˆë‹¤.\n"
        "- ì•„ë˜ ëª©ë¡ì€ í•´ë‹¹ ê¸°ì¤€ì„ ì¶©ì¡±í•œ ê³ ê°ì„ **ìœ„í—˜ë„ ìˆœ**ìœ¼ë¡œ ì •ë ¬í•´ ë³´ì—¬ì¤ë‹ˆë‹¤."
    )
elif src == "ae":
    flag_col = "AE_ChurnFlag_dyn" if (use_dynamic and "AE_ChurnFlag_dyn" in filtered.columns) else "AE_ChurnFlag"
    sort_metric = "AE_ReconError" if "AE_ReconError" in filtered.columns else "ChurnRiskScore"
    subset = filtered[filtered.get(flag_col, 0) == 1] if flag_col in filtered.columns else filtered.copy()
    thr_value = float(ae_thr) if (use_dynamic and ae_thr is not None) else (
        float(filtered["AE_ReconError"].quantile(0.95)) if "AE_ReconError" in filtered.columns else None)
    st.markdown(
        "**íŒë‹¨ ê¸°ì¤€ ì•ˆë‚´**\n\n"
        "- AutoencoderëŠ” ì •ìƒ íŒ¨í„´ ëŒ€ë¹„ ì¬êµ¬ì„± ì˜¤ì°¨ê°€ í° ìƒ˜í”Œì„ ì´íƒˆ ì‹ í˜¸ë¡œ ê°„ì£¼í•©ë‹ˆë‹¤.\n"
        "- ì•„ë˜ ëª©ë¡ì€ í•´ë‹¹ ê¸°ì¤€ì„ ì¶©ì¡±í•œ ê³ ê°ì„ **ìœ„í—˜ë„ ìˆœ**ìœ¼ë¡œ ì •ë ¬í•´ ë³´ì—¬ì¤ë‹ˆë‹¤."
    )
else:
    flag_col = "Both_ChurnFlag_dyn" if (use_dynamic and "Both_ChurnFlag_dyn" in filtered.columns) else "Both_ChurnFlag"
    sort_metric = "ChurnRiskScore"
    subset = filtered[filtered.get(flag_col, 0) == 1] if flag_col in filtered.columns else filtered.copy()
    thr_value = None
    st.markdown(
        "**íŒë‹¨ ê¸°ì¤€ ì•ˆë‚´**\n\n"
        "- **ë‘ ëª¨ë¸ ëª¨ë‘ ì´íƒˆ**ë¡œ íŒë‹¨ëœ ê³ ê°ì„ ê³ ì‹ ë¢°êµ°ìœ¼ë¡œ ì •ì˜í•©ë‹ˆë‹¤.\n"
        "- ì•„ë˜ ëª©ë¡ì€ ê³ ì‹ ë¢°êµ° ì¤‘ **ì´íƒˆìœ„í—˜ì ìˆ˜**ê°€ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬í•©ë‹ˆë‹¤."
    )

# ===== ìŠ¤ëƒ…ìƒ· íŒ¨ë„ =====
colA, colB, colC = st.columns(3)
target_n = int(len(subset))
total_n = int(len(filtered)) if len(filtered) else 1
colA.metric("ëŒ€ìƒ ê³ ê° ìˆ˜", f"{target_n:,}", f"{(target_n/total_n*100):.2f}%")
if thr_value is not None and np.isfinite(thr_value):
    colB.metric("ì‚¬ìš© ì„ê³„ê°’", f"{thr_value:.4f}")
else:
    colB.metric("ì‚¬ìš© ì„ê³„ê°’", "â€”")
if sort_metric in filtered.columns:
    s_all = pd.to_numeric(filtered[sort_metric], errors="coerce")
    s_sub = pd.to_numeric(subset[sort_metric], errors="coerce")
    m_all = float(s_all.mean()) if s_all.notna().any() else 0.0
    m_sub = float(s_sub.mean()) if s_sub.notna().any() else 0.0
    delta_pct = ((m_sub - m_all)/m_all*100.0) if m_all > 0 else 0.0
    colC.metric(
        f"{KOR_COL.get(sort_metric, sort_metric)} í‰ê· ",
        f"{m_sub:.4f}",
        f"{delta_pct:+.1f}% vs ì „ì²´"
    )

# ===== í•œê¸€ í°íŠ¸ ìë™ ì„¤ì • (ê·¸ë˜í”„ìš©) =====
def _set_korean_font_if_available():
    try:
        import matplotlib.pyplot as plt
        from matplotlib import font_manager as fm
        candidates = [
            "Apple SD Gothic Neo", "Malgun Gothic",
            "NanumGothic", "Nanum Gothic", "Noto Sans CJK KR"
        ]
        available = {f.name for f in fm.fontManager.ttflist}
        for name in candidates:
            if name in available:
                plt.rcParams["font.family"] = name
                break
        plt.rcParams["axes.unicode_minus"] = False
    except Exception:
        pass

# ===== (ì„ íƒ) ê·¸ë˜í”„ ë³´ê¸° + ìë™ í•´ì„ =====
show_plot = st.toggle("ê·¸ë˜í”„ ë³´ê¸°(ì„ íƒ)", value=False)
if show_plot and (sort_metric in filtered.columns):
    try:
        import matplotlib.pyplot as plt
        _set_korean_font_if_available()

        vals = pd.to_numeric(filtered[sort_metric], errors="coerce").dropna()
        if len(vals) > 0:
            fig, ax = plt.subplots(figsize=(9.5, 3.6), dpi=120)
            ax.hist(vals, bins=30)
            title_key = KOR_COL.get(sort_metric, sort_metric)
            if thr_value is not None and np.isfinite(thr_value):
                ax.axvline(thr_value, linestyle="--")
                ax.set_title(f"{title_key} ë¶„í¬ (ì ì„ =ì„ê³„)", fontsize=14, pad=8)
            else:
                ax.set_title(f"{title_key} ë¶„í¬", fontsize=14, pad=8)
            fig.tight_layout()
            st.pyplot(fig, use_container_width=True)

            q50 = float(vals.quantile(0.50))
            q90 = float(vals.quantile(0.90))
            q95 = float(vals.quantile(0.95))
            mean = float(vals.mean())
            std  = float(vals.std(ddof=1)) if len(vals) > 1 else 0.0
            skew = float(vals.skew()) if len(vals) > 2 else 0.0
            skew_txt = (
                "ìš°ì¸¡ ê¼¬ë¦¬(í° ê°’ì— ì†Œìˆ˜ ì§‘ì¤‘)" if skew > 0.5
                else ("ì¢Œì¸¡ ê¼¬ë¦¬(ì‘ì€ ê°’ì— ì†Œìˆ˜ ì§‘ì¤‘)" if skew < -0.5 else "ëŒ€ì¹­ì— ê°€ê¹Œì›€")
            )

            if thr_value is not None and np.isfinite(thr_value):
                above = int((vals >= thr_value).sum())
                pct_above = 100.0 * above / len(vals)
                thr_pct = 100.0 * (vals <= thr_value).mean()
                st.markdown(
                    f"""
**ê·¸ë˜í”„ í•´ì„**
- ë¶„í¬ í˜•íƒœ: **{skew_txt}** *(skew={skew:.2f})*
- ì¤‘ì•™ê°’/ìƒìœ„ ë¶„ìœ„(90/95): **{q50:.4f} / {q90:.4f} / {q95:.4f}**
- ì„ê³„ê°’ ìœ„ì¹˜: ë°ì´í„°ì˜ **ì•½ {thr_pct:.1f}í¼ì„¼íƒ€ì¼**
- ì„ê³„ ì´ìƒ ê³ ê° ë¹„ì¤‘: **{above:,}ëª… ({pct_above:.2f}%)**
                    """.strip()
                )
            else:
                st.markdown(
                    f"""
**ê·¸ë˜í”„ í•´ì„**
- ë¶„í¬ í˜•íƒœ: **{skew_txt}** *(skew={skew:.2f})*
- ì¤‘ì•™ê°’/ìƒìœ„ ë¶„ìœ„(90/95): **{q50:.4f} / {q90:.4f} / {q95:.4f}**
- í˜„ì¬ ì„¹ì…˜ì€ ì„ê³„ê°’ ì—†ì´ **ì´íƒˆìœ„í—˜ì ìˆ˜ ìƒìœ„** ê¸°ì¤€ìœ¼ë¡œ ëª©ë¡ì´ ì •ë ¬ë©ë‹ˆë‹¤.
                    """.strip()
                )

            if src == "if":
                st.caption(
                    "â„¹ï¸ IF ì ìˆ˜ëŠ” ê²©ë¦¬ ê¹Šì´ì— ê¸°ë°˜í•©ë‹ˆë‹¤. "
                    "ì„ê³„ê°’ì„ ë‚®ì¶”ë©´ íƒì§€ í­ì´ ë„“ì–´ì§€ê³ (ì¬í˜„ìœ¨â†‘), ë†’ì´ë©´ ì—„ê²©í•´ì§‘ë‹ˆë‹¤(ì •ë°€ë„â†‘)."
                )
            elif src == "ae":
                st.caption(
                    "â„¹ï¸ AE ì˜¤ì°¨ëŠ” ì •ìƒ íŒ¨í„´ì—ì„œ ë²—ì–´ë‚œ ì •ë„ì…ë‹ˆë‹¤. "
                    "ì„ê³„ê°’ì„ ë‚®ì¶”ë©´ ë” ë§ì€ ì´ìƒ ì‹ í˜¸ë¥¼ í¬ì°©í•©ë‹ˆë‹¤."
                )
            else:
                st.caption(
                    "â„¹ï¸ ê³ ì‹ ë¢°êµ°ì€ IFì™€ AE ëª¨ë‘ ì„ê³„ ì´ìƒì¸ ê³ ê°ì…ë‹ˆë‹¤. "
                    "ìƒë‹¨ í‘œì˜ â€˜ë¦¬ìŠ¤í¬ìš”ì¸â€™ íƒœê·¸ë¡œ ê´€ë¦¬ ìš°ì„ ìˆœìœ„ë¥¼ í™•ì¸í•˜ì„¸ìš”."
                )
    except Exception:
        pass

st.markdown("---")

# ===== ìœ„í—˜ë„ ìˆœ ë¦¬ìŠ¤íŠ¸ (ë¦¬ìŠ¤í¬ ìš”ì¸ íƒœê·¸ + ìš°ì„  ì—°ë½ë„ ì§€í‘œ)
# ì •ë ¬ ë° ìˆœìœ„ì ìˆ˜ ìƒì„±
if sort_metric in subset.columns:
    subset = subset.sort_values(sort_metric, ascending=False)
    subset["__rank_score__"] = subset[sort_metric]
elif "ChurnRiskScore" in subset.columns:
    subset = subset.sort_values("ChurnRiskScore", ascending=False)
    subset["__rank_score__"] = subset["ChurnRiskScore"]
else:
    subset["__rank_score__"] = 0.0

# ê³ ê°ID ê²°ì¸¡ ì œê±°
if "CustomerID_clean" in subset.columns:
    subset = subset[subset["CustomerID_clean"].notna()]
elif "CustomerID" in subset.columns:
    subset = subset[subset["CustomerID"].notna()]

top_k = st.slider("í‘œì‹œ ê±´ìˆ˜", min_value=10, max_value=500, value=100, step=10)

# ë¦¬ìŠ¤í¬ íƒœê·¸ ê¸°ì¤€(ë¶„ìœ„) ê³„ì‚° â€” ì „ì²´(í•„í„°ì ìš© í›„) ë¶„í¬ ê¸°ì¤€
def qdict(series):
    s = pd.to_numeric(series, errors="coerce").dropna()
    if s.empty: return None
    return {
        "p10": float(s.quantile(0.10)), "p20": float(s.quantile(0.20)),
        "p80": float(s.quantile(0.80)), "p90": float(s.quantile(0.90))
    }

q = {}
for c in [
    "NegativeExperienceIndex","AverageSatisfactionScore","EmailEngagementRate",
    "CSFrequency","TotalEngagementScore","AvgPurchaseInterval","PurchaseFrequency"
]:
    if c in filtered.columns:
        q[c] = qdict(filtered[c])

def make_risk_tags(row) -> tuple[str, str]:
    tags_html, tags_text = [], []
    def add(label, color):
        tags_html.append(f"<span class='tag tag-{color}'>{label}</span>")
        tags_text.append(label)

    ne = row.get("NegativeExperienceIndex")
    if ne is not None and "NegativeExperienceIndex" in q and q["NegativeExperienceIndex"]:
        if pd.notna(ne) and ne >= q["NegativeExperienceIndex"]["p80"]:
            add("ë¶€ì •ê²½í—˜â†‘", "red")

    sat = row.get("AverageSatisfactionScore")
    if sat is not None and "AverageSatisfactionScore" in q and q["AverageSatisfactionScore"]:
        if pd.notna(sat) and sat <= q["AverageSatisfactionScore"]["p20"]:
            add("ë§Œì¡±ë„â†“", "amber")

    em = row.get("EmailEngagementRate")
    if em is not None and "EmailEngagementRate" in q and q["EmailEngagementRate"]:
        if pd.notna(em) and em <= q["EmailEngagementRate"]["p20"]:
            add("ì´ë©”ì¼ì°¸ì—¬â†“", "amber")

    cs = row.get("CSFrequency")
    if cs is not None and "CSFrequency" in q and q["CSFrequency"]:
        if pd.notna(cs) and cs >= q["CSFrequency"]["p80"]:
            add("ìƒë‹´ë¹ˆë„â†‘", "amber")

    te = row.get("TotalEngagementScore")
    if te is not None and "TotalEngagementScore" in q and q["TotalEngagementScore"]:
        if pd.notna(te) and te <= q["TotalEngagementScore"]["p20"]:
            add("ì°¸ì—¬ì ìˆ˜â†“", "gray")

    ap = row.get("AvgPurchaseInterval")
    if ap is not None and "AvgPurchaseInterval" in q and q["AvgPurchaseInterval"]:
        if pd.notna(ap) and ap >= q["AvgPurchaseInterval"]["p80"]:
            add("êµ¬ë§¤ê°„ê²©â†‘", "gray")

    pf = row.get("PurchaseFrequency")
    if pf is not None and "PurchaseFrequency" in q and q["PurchaseFrequency"]:
        if pd.notna(pf) and pf <= q["PurchaseFrequency"]["p20"]:
            add("êµ¬ë§¤ë¹ˆë„â†“", "gray")

    return " ".join(tags_html), ", ".join(tags_text)

top_sub = subset.head(top_k).copy()
html_tags, text_tags = [], []
for _, r in top_sub.iterrows():
    h, t = make_risk_tags(r)
    html_tags.append(h)
    text_tags.append(t)
top_sub["__tags_html__"] = html_tags
top_sub["__tags_text__"] = text_tags

# ===== ìš°ì„  ì—°ë½ë„(0-100) ê³„ì‚° (5~95 ë¶„ìœ„ ê¸°ì¤€ ì •ê·œí™”)
def _priority_index_from_quantiles(ref_series: pd.Series, values: pd.Series,
                                   q_low=0.05, q_high=0.95) -> pd.Series:
    ref = pd.to_numeric(ref_series, errors="coerce")
    val = pd.to_numeric(values, errors="coerce")
    if ref.notna().any():
        lo = float(ref.quantile(q_low)); hi = float(ref.quantile(q_high))
        if not np.isfinite(lo) or not np.isfinite(hi) or hi <= lo:
            lo, hi = float(ref.min()), float(ref.max())
    else:
        lo, hi = 0.0, 1.0
    rng = hi - lo if (hi > lo) else 1.0
    idx = ((val - lo) / rng).clip(0, 1) * 100.0
    return idx.round(0).fillna(0)

if sort_metric in filtered.columns:
    top_sub["__priority_idx__"] = _priority_index_from_quantiles(
        filtered[sort_metric], top_sub[sort_metric]
    )
else:
    top_sub["__priority_idx__"] = 0

# ìš°ì„  ì—°ë½ë„ HTML(ë§‰ëŒ€+ë°°ì§€) ìƒì„±
def _priority_tier(idx: float):
    if idx >= 90: return "ìµœìš°ì„ ", "rb-red"
    if idx >= 70: return "ë†’ìŒ", "rb-orange"
    if idx >= 40: return "ë³´í†µ", "rb-amber"
    return "í›„ìˆœìœ„", "rb-gray"

def _mk_priority_html(idx: float, raw: float, thr: float | None):
    """ìš°ì„  ì—°ë½ë„ í‘œì‹œìš© HTML â€“ ë°°ì§€ë§Œ í‘œì‹œ(ì ìˆ˜ í…ìŠ¤íŠ¸ ì—†ìŒ)."""
    label, css = _priority_tier(float(idx))
    tip = f"ìš°ì„  ì—°ë½ ì ìˆ˜ {int(idx)}/100"
    if pd.notna(raw):
        tip += f" | ëª¨ë¸ ì›ì ìˆ˜ {float(raw):.4f}"
    if thr is not None and np.isfinite(thr):
        tip += f" | ì„ê³„ {float(thr):.4f}"

    # âœ… ë°°ì§€ í•˜ë‚˜ë§Œ ë Œë”ë§ (ìµœìš°ì„ /ë†’ìŒ/ë³´í†µ/í›„ìˆœìœ„)
    return f"<span class='rbadge {css}' title='{tip}'>{label}</span>"

top_sub["__priority_html__"] = [
    _mk_priority_html(
        idx,
        raw=top_sub.iloc[i][sort_metric] if sort_metric in top_sub.columns else np.nan,
        thr=thr_value
    )
    for i, idx in enumerate(top_sub["__priority_idx__"])
]

# ===== í‘œ êµ¬ì„± (ê´€ë¦¬ì ì¹œí™”)
desired = [
    "CustomerID_clean",
    "GenderLabel",
    "Age",
    "RepeatAndPremiumFlag",
    "CustomerLifetimeValue",
    "TotalPurchases",
    "PurchaseFrequency",
    "CSFrequency",
    "AverageSatisfactionScore",
    "NegativeExperienceIndex",
    "EmailEngagementRate",
    "TotalEngagementScore",
    "ChurnRiskScore",
    "__priority_idx__",
    "__priority_html__",
]
cols_to_show = [c for c in desired if c in top_sub.columns]
view_df = top_sub[cols_to_show].copy()

if view_df.empty:
    st.info("í˜„ì¬ ì¡°ê±´ì—ì„œ í‘œì‹œí•  ê³ ê°ì´ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

# ìˆœë²ˆ + ìƒì„¸ ë§í¬ + ë¦¬ìŠ¤í¬ ìš”ì¸ + ìš°ì„  ì—°ë½ë„(HTML)
view_df.insert(0, "", np.arange(1, len(view_df) + 1))
view_df["ê³ ê°ID"] = top_sub["CustomerID_clean"].apply(
    lambda cid: f"<a href='/Customer_Detail?customer_id={quote(str(cid))}' target='_self'>{cid}</a>"
)
view_df["ë¦¬ìŠ¤í¬ìš”ì¸"] = top_sub["__tags_html__"]
view_df["ìš°ì„  ì—°ë½ë„"] = top_sub["__priority_html__"]

# ë¶ˆí•„ìš”í•œ ë‚´ë¶€ ì»¬ëŸ¼ ì œê±° ë° ë¼ë²¨ë§
view_df.drop(columns=["CustomerID_clean","__priority_html__","__priority_idx__"], inplace=True, errors="ignore")
view_df = rename_for_display(view_df)

# í‘œ í‘œì‹œ ìˆœì„œ: ìˆœìœ„ â†’ ê³ ê°ID â†’ ìš°ì„  ì—°ë½ë„ â†’ ë¦¬ìŠ¤í¬ìš”ì¸ â†’ ë‚˜ë¨¸ì§€
display_cols = ["", "ê³ ê°ID", "ìš°ì„  ì—°ë½ë„", "ë¦¬ìŠ¤í¬ìš”ì¸"] + [
    c for c in view_df.columns if c not in ("","ê³ ê°ID","ìš°ì„  ì—°ë½ë„","ë¦¬ìŠ¤í¬ìš”ì¸")
]

# ìˆ«ì í¬ë§·
age_label = KOR_COL.get("Age", "Age")
clv_label = KOR_COL.get("CustomerLifetimeValue", "CustomerLifetimeValue")
tp_label  = KOR_COL.get("TotalPurchases", "TotalPurchases")

fmt_map = {}
for c in display_cols:
    if c in ("","ê³ ê°ID","ì„±ë³„","ìš°ì„  ì—°ë½ë„","ë¦¬ìŠ¤í¬ìš”ì¸"):
        continue
    if c in (age_label, tp_label):
        fmt_map[c] = "{:.0f}"
    elif c == clv_label:
        fmt_map[c] = "{:,.0f}"
    else:
        fmt_map[c] = "{:.2f}"

styler = (
    view_df[display_cols]
    .style
    .format(fmt_map)
    .hide(axis="index")
    .set_table_attributes('class="dataframe"')
)

table_html = styler.to_html(escape=False)

st.markdown(
    """
    <style>
    /* ê°€ë¡œ ìŠ¤í¬ë¡¤ ì»¨í…Œì´ë„ˆ */
    .risky-scroll {
      width: 100%;
      overflow-x: auto;       /* ğŸ”¥ ì—¬ê¸°ì„œ ê°€ë¡œ ìŠ¤í¬ë¡¤ ê°•ì œ */
    }

    .risky-scroll table {
      border-collapse: collapse;
      width: auto !important;
      min-width: 1500px;      /* í™”ë©´ë³´ë‹¤ ë„“ê²Œ ë§Œë“¤ì–´ì•¼ ìŠ¤í¬ë¡¤ì´ ìƒê¹€. í•„ìš”í•˜ë©´ 1800 ë“±ìœ¼ë¡œ ì¡°ì • */
      max-width: none !important;
      table-layout: auto;
    }

    .risky-scroll th,
    .risky-scroll td {
      padding: 10px 12px !important;
      line-height: 1.45;
      vertical-align: middle;
      white-space: nowrap;    /* ì¤„ë°”ê¿ˆ ëŒ€ì‹  ê°€ë¡œë¡œ ì­‰ í¼ì¹¨ */
    }

    /* ë¦¬ìŠ¤í¬ ìš”ì¸ íƒœê·¸ */
    .tag {
      display: inline-block;
      padding: 2px 6px;
      margin-right: 4px;
      margin-bottom: 2px;
      border-radius: 6px;
      font-size: 12px;
    }
    .tag-red   { background: rgba(255, 59, 48, 0.18); border: 1px solid rgba(255, 59, 48, 0.35); }
    .tag-amber { background: rgba(255,149,  0, 0.18); border: 1px solid rgba(255,149,  0, 0.35); }
    .tag-gray  { background: rgba(128,128,128,0.18); border: 1px solid rgba(128,128,128,0.35); }

    /* ìš°ì„  ì—°ë½ë„ ë§‰ëŒ€ + ë°°ì§€ */
    .rwrap { display:flex; align-items:center; gap:8px; }
    .rbar  { flex:1; height:10px; background:rgba(0,0,0,0.06); border-radius:999px; overflow:hidden; }
    .rbar .fill { height:100%; }
    .fill.rb-red    { background: rgba(255, 59, 48, 0.60); }
    .fill.rb-orange { background: rgba(255,149,  0, 0.60); }
    .fill.rb-amber  { background: rgba(255,204,  0, 0.55); }
    .fill.rb-gray   { background: rgba(128,128,128,0.45); }

    .rbadge {
      padding: 2px 6px;
      border-radius: 6px;
      font-size: 12px;
      line-height: 1;
      border:1px solid transparent;
    }
    .rbadge.rb-red    { background: rgba(255, 59, 48, 0.18); border-color: rgba(255, 59, 48, 0.35); }
    .rbadge.rb-orange { background: rgba(255,149,  0, 0.18); border-color: rgba(255,149,  0, 0.35); }
    .rbadge.rb-amber  { background: rgba(255,204,  0, 0.18); border-color: rgba(255,204,  0, 0.35); }
    .rbadge.rb-gray   { background: rgba(128,128,128,0.18); border-color: rgba(128,128,128,0.35); }
    </style>
    """,
    unsafe_allow_html=True,
)

st.markdown(
    f"<div class='risky-scroll'>{table_html}</div>",
    unsafe_allow_html=True,
)

# ===== CSV ë‹¤ìš´ë¡œë“œ (íƒœê·¸=í…ìŠ¤íŠ¸, ìš°ì„  ì—°ë½ë„/ì›ì ìˆ˜ í¬í•¨) =====
export_df = view_df.copy()
export_df.rename(columns={"": "ìˆœìœ„"}, inplace=True)
export_df.insert(1, "CustomerID", export_df["ê³ ê°ID"].str.extract(r'>(.*?)<')[0])

export_df.drop(columns=["ìš°ì„  ì—°ë½ë„"], inplace=True)
export_df.insert(2, "ìš°ì„ ì—°ë½ë„(0-100)", top_sub["__priority_idx__"].astype(int).values)

raw_label = {
    "if":   f"ì›ì ìˆ˜({KOR_COL.get('IF_AnomalyScore','IF_AnomalyScore')})",
    "ae":   f"ì›ì ìˆ˜({KOR_COL.get('AE_ReconError','AE_ReconError')})",
    "both": f"ì›ì ìˆ˜({KOR_COL.get('ChurnRiskScore','ChurnRiskScore')})",
}.get(src, "ì›ì ìˆ˜")
raw_series = (
    pd.to_numeric(top_sub[sort_metric], errors="coerce").round(6)
    if sort_metric in top_sub.columns else pd.Series([np.nan]*len(top_sub))
)
export_df.insert(3, raw_label, raw_series.values)
export_df["ë¦¬ìŠ¤í¬ìš”ì¸"] = top_sub["__tags_text__"].values

csv_bytes = export_df.to_csv(index=False).encode("utf-8-sig")
st.download_button(
    "â¬‡ï¸ CSV ë‚´ë ¤ë°›ê¸°",
    data=csv_bytes,
    file_name=f"{src}_risky_customers.csv",
    mime="text/csv"
)